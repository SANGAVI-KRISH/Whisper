{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Uninstall any incorrect Whisper library\n",
        "!pip uninstall whisper -y\n",
        "\n",
        "# Install the correct OpenAI Whisper library and ffmpeg\n",
        "!pip install git+https://github.com/openai/whisper.git ffmpeg-python\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JB2jhroZOdKQ",
        "outputId": "05df5d20-84f8-4e5d-f130-cae83c192ec9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping whisper as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-y9io725a\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-y9io725a\n",
            "  Resolved https://github.com/openai/whisper.git to commit c0d2f624c09dc18e709e37c2ad90c039a4eb72a2\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (0.11.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (3.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.12/dist-packages (from triton>=2->openai-whisper==20250625) (75.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper==20250625) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper==20250625) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper==20250625) (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (1.11.1.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper==20250625) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper==20250625) (3.0.3)\n",
            "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=08c51a57f2dcb23e383f04c1340721b2b28184db55956c277f2d5d215b66fd5b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-q5ntpjnn/wheels/c3/03/25/5e0ba78bc27a3a089f137c9f1d92fdfce16d06996c071a016c\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: ffmpeg-python, openai-whisper\n",
            "Successfully installed ffmpeg-python-0.2.0 openai-whisper-20250625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import whisper\n",
        "\n",
        "# Upload audio file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the uploaded file name\n",
        "audio_file = list(uploaded.keys())[0]\n",
        "print(f\"Uploaded file: {audio_file}\")\n",
        "\n",
        "# Load the Whisper model (you can also use \"tiny\", \"small\", \"medium\", \"large\")\n",
        "model = whisper.load_model(\"base\")\n",
        "\n",
        "# Transcribe the uploaded audio file\n",
        "result = model.transcribe(audio_file)\n",
        "\n",
        "# Print the transcription\n",
        "print(\"Transcription:\")\n",
        "print(result[\"text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "RQX12XH9OoOC",
        "outputId": "d50e070b-798f-4d18-96be-b71dc887d2da"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-86614724-35fd-4d22-902b-03703ff42c43\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-86614724-35fd-4d22-902b-03703ff42c43\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 6 Secrets of Happy Couples-English Listening Practice Ep 827-356da2 (1).mp3 to 6 Secrets of Happy Couples-English Listening Practice Ep 827-356da2 (1).mp3\n",
            "Uploaded file: 6 Secrets of Happy Couples-English Listening Practice Ep 827-356da2 (1).mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:03<00:00, 43.2MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription:\n",
            " Would you thank your partner for cooking the dinner? Welcome to Adept English. I'm Hilary and this is a Learn English Through Listening podcast. Saying thank you shows respect and keeps both people in a couple relationship feeling valued. Today some great relationship advice and the opportunity to learn some useful English words about love, family and feelings. Saying thank you each day makes relationships stronger. In English a quick thanks has real power. So today's topic, how do you keep your relationship with your partner, your husband or your wife healthy? Hello, I'm Hilary and you're listening to Adept English. We will help you to speak English fluently or you have to do is listen. So start listening now and find out how it works. And this is from a newspaper that is free in the UK. That's the Metro and an article in the Metro describes six conversations that people in the happiest relationships have every day. It's important to look after your relationships. Fortunately most people these days have the choice about whether they're in a relationship or not. So it's important to keep your relationships psychologically healthy. The Metro is one of my favorite newspapers for interesting articles on relationships and psychological subjects. The Metro is a free tabloid newspaper which became the most read newspaper in the UK in 2017. The Metro is free so it relies on advertising. It had a blip made a loss during COVID but was back profit making again by 2024. If you're in the UK, the Metro newspaper has some interesting stories. And this article was published on the 28th of August 2025 written by Sophie May Williams. I thought I'd share it with you this article. Six conversations that the happiest couples have every day as usual with some insights of my own. Some from my psychotherapy practice. And here again our Listen and Learn strategy will work to help you increase your English vocabulary. Words to do with relationships and feelings today. Don't forget to listen a number of times to make sure any new words stick in your mind. Sophie Williams starts by talking about some of the dangers and difficulties of long term relationships. She says when you first meet someone there are just so many things to talk about. Likes and dislikes, hobbies, hopes and dreams. Everything is exciting and new but as the years go by do couples that see O-U-P-L-E do couples run out of conversation. The danger is that you know each other so well that there are no secrets, no surprises. Or another danger your conversation becomes just one long transactional discussion. What do I mean there? I mean talking about logistics, L-O-G-I-S-T-I-C. Who's going to pick up the children? Who's going to get the shopping? What time are you home from work tonight because I want to go out? That's all information exchange which is transactional and couples can fall into this trap once they have children. So how to keep the spark alive? S-P-A-R-K. How to keep it interesting? Well let's credit the source of this good advice. Sophie May Williams was talking to Dr. Sheena Kumar who is a counselling psychologist. That's a very similar training to my psychotherapy training. And Dr. Kumar suggests that there are six types of conversation that happy couples tend to have with one another each day. Let's have a look at what they are. Number one, happy couples do daily check-ins. Dr. Kumar talks about small daily check-ins. And while you might check in your bags at the airport, if you check in with a friend or partner, it means that you give them regular updates about what's going on for you, about your day, about your experiences, your life in general. Dr. Kumar says, research finds that couples who regularly check in with one another feel more emotionally connected. And apparently a study done in 2005 showed that couples who check in regularly are more satisfied with their relationships and have better communication. By contrast, relationships where people didn't check in regularly with their partner were said to like emotional intimacy. To have more conflict, less sex and more loneliness and disconnection, it all makes sense. And it may mean just checking in with your partner about what your trip to the dentist was like or what happened on the train or in the supermarket or at work today. We call these minutiai, M-I-N-U-T-I-A-E from the Latin, meaning tiny things, little things, little everyday things. But communicating these in an intimate and close relationship is really important. It's one of the things that keeps your relationship safe. And if you like what we do and you would like to support adaptinglish, apart from subscribing to our paid subscription service, the following things are really helpful to us. When you listen to a podcast or watch a video, please watch right into the end if you can. And we also appreciate it if you subscribe to adaptinglish on whatever platform you listen. It's hard out there. It's difficult getting noticed. But the algorithms do take notice of how long you watch, whether we can hold your attention as well as how many subscribers the channel has. We would like to reach a bigger audience. Much of our material is free and it will help more people become fluent in English. The other really helpful thing you can do for us is share our podcasts on Spotify. Use the share button to share them with friends and family that you think might be interested. Thank you for helping a debt English continue to bring you creative material or English language learners. Number two, saying thank you. Dr. Kumar says that saying thank you to your partner, to your husband and wife for the small everyday things that they do is very important. It might be making the dinner, putting on the washing, emptying the dishwasher or giving you a lift. Apparently, couples who notice what the other one does and say thank you to one another. They're more bonded B-O-N-D-E-D. They have stronger bonds, that means. And they're more satisfied in their relationship. But warns Dr. Kumar, people forget to say thank you. I think this one is particularly important where the arrangement in a couple is that one goes out to work and one stays home, keeps house, looks after the children. Both of these roles have value and are necessary and should have equal respect. Sometimes though, it's not what happens in practice. Thanking your partner for whatever they contribute, whether that's getting up early every day and getting on the train and going to work, having lots of stress, or whether it's cleaning the bathroom and picking your daughter up from school, taking her to a piano lesson and doing homework. Everything counts, everything is a contribution that deserves to be respected, valued and acknowledged. Number three, shared humour, that's H-U-M-O-U-R. Humor is what makes us laugh. Just like with your friends, having lots of humour, shared jokes and laughter. Well, this acts like glue in a relationship. That's glue, G-L-U-E. We all like and feel closer to the people who make us laugh. This could, say the article in the Metro, be reminiscing about memories, or recalling a joke or a funny situation that only the two of you understand. When you laugh, that's to laugh, L-A-U-G-H, it releases endorphins, EN, D-O-R-P-H-I-N. Endorphins are the natural chemicals produced by the body that help relieve pain and reduce stress, often referred to as feel good hormones. Dr. Kuhmar says that humour, or being funny, helps lower stress and helps partner see each other as on the same team. I agree. I think humour, as long as it's not at anyone's expense, is very bonding. It bonds you together. Number four, watching TV. Okay, so watching too much television together and not talking, is not recommended and perhaps could be a problem. But Dr. Kuhmar encourages couples to watch the same programme or series on TV and to talk about it afterwards. Enjoying a series together, talking about it afterwards gives you a shared experience and something to discuss. Chatting about your favourite entertainment can actually be a good thing for your relationship, having an appointment on the sofa at a particular time in the evening and sitting down and watching something together can be a nice end to the day. Number five, dreams and personal goals. Of course, it's important to talk about these things at the start of a relationship, particularly things like whether or not you want to have children, where you want to live, what you imagine will happen with your work and where it will locate you. All important topics at the beginning. It's good to share generally what do you want in life. But when you've been together a long time, you may be in a new phase, a new part of your life and talking again about your hopes and dreams is important because they will have changed. It checks out whether you're still on the same page, still wanting to head in a similar direction in life. Dr. Kuh Marseilles, happy couples support each other's individual growth. Talking about hopes and ambitions helps each partner see beyond their role in the relationship. It creates a joint division of the future, which is really important. Number six, affection and words of affirmation. If you've ever come across the five love languages, you may recognize this expression, words of affirmation. It basically means saying nice things to someone, affirming who they are. That's to affirm AFFIRM. It means giving one another compliments, saying nice things. Dr. Kuh Marseilles, that simple words of affection matter. And if you're not comfortable saying nice things, then affection, AFFIRCTIN, can be shown through touch, lots of hugs, etc. Dr. Kuh Mar again, daily expressions of love, release oxytocin. That's OXYTocin, and oxytocin reinforces closeness and trust. So don't forget to pay attention to your partner. Give them affection, praise them, and say nice things to them. Complement each other regularly. It's a good thing to do. So there you are. All the help you need to maintain a positive relationship, a relationship that's in a healthy condition. Let us know your thoughts on this, especially if you have any advice or tips to add. And don't forget to listen several times to improve your English. Enough for now. Have a lovely day. Speak to you again soon. Goodbye. Thank you so much for listening. Please help me tell others about this podcast by reviewing or rating it. And please share it on social media. You can find more listening lessons and a free English course at adeptinglish.com.\n"
          ]
        }
      ]
    }
  ]
}